# creditCardFraudulent
Machine Learning Algorithms to Predict Fraudulent Claims

# Executive Summary

## Business problem: 
Credit card companies are actively trying to recognize fraudulent credit card transactions to prevent customer grief for the charges they have not purchased. By applying machine learning techniques on credit card transactional data future fraudulent purchases can be detected more efficiently and quickly. 

## Data: 
The Credit Card Fraud Detection dataset contains transactions made by credit cards from European cardholders for the month of September 2013. This data is imported from a public repository found on Kaggle. The dataset encompasses credit transactions that occurred in two days. The dataset is presented in a clean and structured format, and comes in a shape of nearly 300K rows of transactions with 30 featured columns and one target column. The target column is populated with either a Fraud, or a Non-Fraud label. This column is unbalance, with nearly all transactions declared as Non-Fraud.

## Dataset
As mentioned, the dataset that will be explored contains transactions made by credit cards by European cardholders for the month of September 2013. The dataset encompasses credit transactions that occurred in two days. Of the entire 284,807 transactions 492 are frauds. This dataset is quite unbalanced with an actual true fraud case accounting for 0.172% of all transactions.
The dataset is in a clean csv file, found on Kaggle. The data only contains numerical input variables which are a result of a PCA transformation [5]. The data lacks complete information, because of data masking, due to data security (personal confidentiality). The only features that have not been transformed with  PCA are ‘Time’ and ‘Amount.’  Feature ‘Time’ contains the seconds elapsed between each transaction and the first transaction in the dataset. While Feature ‘Amount’ is the transaction amount. Lastly, the predicting feature ‘Class’ is the response variable and it takes a value of 1 for fraud and 0 otherwise.

## Methods
Undersampling was performed to help alleviate and enlighten features in the model. Additionally, normalization was applied to select features. Machine learning algorithms were applied to three versions of the dataset. Various techniques are implemented, but Support Vector Machine and Random Forest algorithms are broadly explored. 
Support Vector Machine classifier and Logistic Regression presented the best model, with AUPRCs of 0.93.

## Recommendations
The following are couple recommendations to consider when further researching the topic of fraudulent credit card detection:
•	Further exploratory research on Support Vector Machines can be done, to further improve the precision and recall of the model.
•	Implement hierarchical clustering to help with the biases. Hierarchical clustering can remove undeniable transactions.

# Introduction
In the modern world, purchasers are increasingly using their credit cards [1]. Americans currently use Visa-branded and Mastercard-branded credit cards more than 33 billion times per year [2]. Additionally, over 70% of purchasers claim they own credit cards [3]. Due to the 2020 Global Pandemic, individuals are more interested in hand free options, and since online ordering predominately does not accept cash, these usage numbers are surely to change. [4] [5]. 
Most purchases done with credit cards are made by the cardholder or by an authorized users. Wrongdoers nefariously use credit card and/or online credit info for criminal activities. The main criminal activity that is associated with credit cards is fraudulent transactions. A fraudulent transactions is an unauthorized transaction on debit or credit cards. These unauthorized transactions can include cards that are stolen, lost, fake or dishonest claims. Credit card fraud cost users and banks billions of dollars per year [6]. Nevertheless, it seems there are trends amongst fraudulent transactions which can be utilized by policing services [7].
Machine Learning (ML) is the process of digitalized learning. Based on mathematical models, learning is conducted on a dataset then is implemented, usually on testing data, to make predictions without human intervention. This process of learning is used in order to look for patterns, trends, and habits in data to make better decisions in the future. Industries with larger amounts of data have recognized the value ML has to offer. It is seen in financial services, healthcare, transportation, artificial intelligence, sales and marketing [8]. 
	Merging transaction credit card data with fraudulent claims to ML algorithms, trends can be discovered. With these discoveries, banking and credit card companies can help predict and implement structures to prevent or reduce the amount of fraudulent transactions; lightening customer and policy contributor grief. 

# Problem Description
The objective of this report is to apply ML techniques on credit card transactional data, with the hopes of accurately detecting fraudulent purchases efficiently. The report is focused on a retro-looking model, that eventually can be implemented into a forward-looking model with live data being streamed and analyzed instantly. Implementation of a model like this can be used to predict and prevent fraudulent claims by locking out credit cards and preventing unwanted purchases, reducing anguish among customers.

## Dataset
The main dataset that has been explored contains transactions made by credit cards from European cardholders for the month of September 2013. The dataset encompasses credit transactions that occurred in two days. Of the entire 284,807 transactions 492 are frauds. This dataset is quite unbalanced with an actual true fraud case accounting for 0.172% of all transactions. 
The credit transactional data is in a clean structured csv file, accessed from Kaggle [9]. The data contains 28 integer features which are a result of a PCA transformation, and 2 non-transformed features. The data lacks complete information because of data masking, due to data security (personal confidentiality). The features that have not been transformed with PCA are ‘Time’ and ‘Amount.’ Feature ‘Time’ contains the seconds elapsed between each transaction and the first transaction in the dataset, as an integer. While Feature ‘Amount’ is the transaction amount. Lastly, the predicting target ‘Class’ is the response variable and it takes a value of 1 for Fraud and 0 for Non-Fraud.

# Solution Description
## Data Cleansing & Transformation
As mentioned in the previous section, the data is presented in a shape of 30 features and roughly 280K rows. Upon inspection the data quality seems to be of a high-caliber. The data looked complete, contained no missing values, and was consistent, features did not seem to contradict each other. Furthermore, the data had only contained integers, no foreign types, such as datetime and characters. Duplicate elimination was the only data cleansing technique performed. Approximately 1000 transactions were dropped. Lastly, outliers were discovered in the data; however, they were kept (see Appendix B-1). 
Due to the clean data, only a few features were transformed. The initial data contained 28 features which had previously undergone PCA transformation. The remaining features ‘Time’ and ‘Amount’ were two features that needed to be scaled. Due to the skewed data and outliers, (see Appendix B-1), RobustScaler from Sklearn was implemented. RobustScaler scales base on percentiles and is therefore not influence by a few numbers of very large outliers. 
Considering the large biased dataset, resampling was performed. A few resampling designs where consider. All designs were undersampled on the Non-Fraud claims. The first design considered was a randomly equaled distributed class size, see Figure 1. The second design considered was a case of 1000 Non-Fraud and 493 Fraud transactions. Since this is a preliminary report only the first design of equally distributed classes was included in the analysis.

## Strategy & ML Models
The ‘Class’ target has only two outcomes; therefore, classification methods were consider. The models exercise were: Logistic Regression, Decision Forest, Random Forest, and Support Vector Classifier (SVC). Various ML methods are implemented to determine which model is more successful in predicting fraudulent credit card transactions. Each model was constructed to predict the target outcome of Fraud or non-Fraud claims. 
Furthermore, three versions of the dataset were considered. The first dataset contain all transactions, and went through data cleaning but was not altered, this dataset is called Non-Transformed. The second dataset includes the data cleansing performed plus the implementation of RobustScaler, which is call Scaled. Last is the dataset that went through all processes including the randomly equal distributed class sizes, called Undersampled.
For all models using the Undersampled data a split 80%-20% for training, and testing respectively. Additionally, all algorithms use a random state taken at 31, and all features are included in the training set.

# Results & Analysis
Data analysis was carried out using Python and Microsoft Azure ML services. Various analyses were performed, each producing different results and interesting insights; an analytical pipeline is seen in Figure 2. Results and analysis focused on three main algorithms: SVC, Random Forest and Logistic Regression and Decision Trees. 
Python scripts were created to perform the bulk of analysis, with Azure services as an auxiliary analysis. For Azure ML services two analytical systems were performed, a cross-validation of various models on the entire dataset, and a train-test split system, with additional Python scripts to match the results performed in Python alone. Finally, when measuring accuracy Area Under the Precision-Recall Curve (AUPRC) was consider. Due to the heavy unbalance data, accuracy is not a feasible metric to judge the models. The AUPRC shows the tradeoff between precision and recalls for different thresholds.
## SVC
In this section, a simple linear SVC model is applied to each of the three datasets. Using Azure, a cross-validation model of 10 folds is performed on the Non-transformed dataset, producing mean precision recall and AUPRC of 0.86, 0.57, and 0.96, respectively. Using the same model with the Scaled dataset, precision, recall and AUPRC equaled 1, 0.97, and 0.99, respectively. Note, that the Scaled dataset performed worse to the biased data when compared Non-transformed dataset.
Next Python was utilized, but this time on the Undersampled dataset. Again a simple linear SVC model was implemented; however, no cross-validation was applied. This model produce a precision of 0.84, a recall of 0.63 and a AUPRC of 0.96, on the test set. The left image of Figure 3 represents a confusion matrix of a test size of 193 transactions, while the right image represents a Precision-Recall Curve. Note that with the Undersample dataset, 96 out of 98 Fraud claims were accurately predicted using a simple linear SVC model.
## Random Forest
Random forest was applied to the Undersampled data. Again Python was used which resulted in test values of, 0.82, 0.62 and 0.96 for precision, recall and AUPRC, respectively (See Appendix C1). Running a Two-Class Random Forest through Azure resulted in means of 0.99, 0.99 and 0.99 for precision, recall and AUPRC, respectively, with both the Non-transformed and Scaled dataset. From these results, the SVC model provide better insights into detecting fraudulent transactions. The model performed on Azure yielded to the biased data.
## Logistic Regression & Decision Tree
Logistic regression was only applied to the Undersampled data and analysis was performed using Python. Applying the 80%-20% split, values for precision, recall, and AUPRC were 0.84, 0.63, and 0.96, respectively. Interesting enough, the values are identical to the simple linear SVC model. Both models predicted 95 fraudulent transactions (See Appendix C2).
Lastly, a decision tree was applied to the Undersampled data. Using Python a GridSearch cross validation model was implemented, with max features set to log2, and sqrt, including both entropy and gini impurity measures and a fold of 5. Results were a precision, recall and AUPRC of 0.82, 0.62, 0.93, respectively. Curiously, this model performed the worse out of all. The precision and recall match the Undersampled Random Forest model, but the AUPRC was worse.
	
# Discussion & Conclusion
Comparing all models, the simple linear SVC and the Logistic Regression presented the best model. With the Unbalanced data the AUPRC was 0.93. Random Forest and Decision Tree provided the worse values. Interestingly, when running the Non-transformed data on Azure, an AUPRC scores of 0.96 was calculated, using the SVC ML algorithm.
Advantages & Limitations
In summary, there seems to be patterns that ML algorithms can discern from the data. These patterns can be implemented onto a full scale system which can detect fraudulent purchases, and prevent further grief on the parties.
Nonetheless, the biased data needs to be further addressed. With such a large bias, it is hard to interpret whether or not the data is not being correctly modelled. Further exploratory research on support vector machines can be done, to further improve the model accuracy. Lastly, hierarchal clustering can be implemented to reduce the biases among the data.

# Bibliography
[1] 	J. J. A. Steele, "Credit card use and availability statistics," Creditcards, January 2020. [Online]. Available: https://www.creditcards.com/credit-card-news/credit-card-use-availability-statistics-1276/. [Accessed July 2020].
[2] 	R. Mckinley, "How Many Card Purchases do Americans Make on Credit Cards and Debit Cards," CardTrak, March 2019. [Online]. Available: https://cardtrak.com/2019/03/14/spending/how-many-card-purchases-on-do-americans-make-on-credit-cards-and-debit-cards/#:~:text=Americans%20currently%20use%20Visa-branded%20and%20Mastercard-branded%20credit%2Fcharge%20cards,made%20annually%20on%20Visa-bran. [Accessed July 2020].
[3] 	B. o. G. o. t. F. R. System, "Report on the Economic Well-Being of U.S. Households in 2016," Federal Reserve, May 2017. [Online]. Available: https://www.federalreserve.gov/publications/files/2016-report-economic-well-being-us-households-201705.pdf. [Accessed July 2020].
[4] 	P. Canada, "COVID-19 pandemic dramatically shifts Canadians' spending habits," Newswire, May 2020. [Online]. Available: https://www.newswire.ca/news-releases/covid-19-pandemic-dramatically-shifts-canadians-spending-habits-855831687.html. [Accessed July 2020].
[5] 	P. Peachey, "Coronavirus: Credit card spending fell 50% at start of lockdown," BBC, July 2020. [Online]. Available: https://www.bbc.com/news/business-53416676. [Accessed August 2020].
[6] 	"Credit Card Fraud Statistics," Shift, July 2020. [Online]. Available: https://shiftprocessing.com/credit-card-fraud-statistics. [Accessed July 2020].
[7] 	D. S., "Police reveal how thieves are quickly spending thousands off stolen credit cards," CTV News, September 2019. [Online]. Available: https://toronto.ctvnews.ca/police-reveal-how-thieves-are-quickly-spending-thousands-off-stolen-credit-cards-1.4613807. [Accessed August 2020].
[8] 	"Machine Learning What it is and why it matters," SAS, 2020. [Online]. Available: https://www.sas.com/en_ca/insights/analytics/machine-learning.html. [Accessed August 2020].
[9] 	M. L. Group, "Anonymized credit card transactions labeled as fraudulent or genuine," Kaggle, 2018. [Online]. Available: https://www.kaggle.com/mlg-ulb/creditcardfraud. [Accessed July 2020].